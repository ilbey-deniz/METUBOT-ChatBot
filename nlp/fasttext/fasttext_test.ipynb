{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import json\n",
    "# fasttext.util.download_model('tr', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = lambda q_vector, vector : dot(q_vector, vector)/(norm(q_vector)*norm(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf idf utility functions\n",
    "\n",
    "# preprocessor for quesiton strings to transform strings to word arrays. \n",
    "# can be replaced with a better one (zemberek)\n",
    "def preProcessor(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# gets the quesitons dictionary and returns dictionary of dictionaries \n",
    "# where subdictionaries consists of keys as each term and values as \n",
    "# number of occurencies  \n",
    "def TF(questions):\n",
    "    result = {}\n",
    "    for category in questions:\n",
    "        result[category] = {}\n",
    "        for question in questions[category]:\n",
    "            term_arr = preProcessor(question)\n",
    "            for i in term_arr:\n",
    "                if i not in result[category]:\n",
    "                    result[category][i] = 1\n",
    "                else:\n",
    "                    result[category][i] += 1\n",
    "    return result\n",
    "\n",
    "def TFxIDF():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model(r'cc.tr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sifre': {'öğrenci': 1, 'şifremi': 3, 'unuttum,': 1, 'nasıl': 2, 'yenileyebilirim?': 1, 'ODTU': 1, 'kullanıcı': 1, 'hatırlamıyorum,': 1, 'ne': 1, 'yapmam': 1, 'lazım?': 1, 'metu': 1, 'mail': 1, 'kaybettim,': 1, 'sıfırlarım?': 1, 'parolamı': 1, 'unuttum': 1, 'metumail': 1, 'şifrem': 1, 'neydi': 1}, 'lisanslı yazılımlar': {'Microsoft': 1, \"Office'i\": 1, 'öğrenci': 1, 'mailimle': 2, 'nasıl': 2, 'kullanabilirim?': 2, 'ücretsiz': 1, 'Autocad': 1, 'kullanmak': 1, 'için': 1, 'ne': 1, 'yapmam': 1, 'lazım': 1, 'exceli': 1, 'metu': 1}, 'wifi': {'meturoam': 1, 'a': 2, 'nasıl': 2, 'bağlanabilirim': 1, 'odtu': 1, 'wifi': 2, 'bağlanırım': 1, 'hangi': 1, 'bağlanmam': 1, 'gerek': 1, 'eduroam': 1, 'şifresi': 1, 'neydi': 1}}\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./question_categories.json\")\n",
    "questions = json.load(f)\n",
    "\n",
    "print(TF(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vectors = {}\n",
    "for key in questions:\n",
    "    question_vectors[key] = []\n",
    "    for q in questions[key]:\n",
    "        question_vectors[key].append(ft.get_sentence_vector(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soru kategorisi: wifi\n",
      "En yakın soru: eduroam şifresi neydi\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Nasıl yardımcı olabilirim?\")\n",
    "q_vector = ft.get_sentence_vector(user_question)\n",
    "\n",
    "most_similar_question = \"\"\n",
    "most_similar_category = \"\"\n",
    "\n",
    "max_similarity = 0\n",
    "category_max_similarity = 0\n",
    "\n",
    "for key in question_vectors:\n",
    "    for vector, question in zip(question_vectors[key], questions[key]):\n",
    "        sim = cos_sim(q_vector, vector)\n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            most_similar_question = question\n",
    "            most_similar_category = key\n",
    "\n",
    "print(\"Soru kategorisi: %s\" % most_similar_category) \n",
    "print(\"En yakın soru: %s\" % most_similar_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
