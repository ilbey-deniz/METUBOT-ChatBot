{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import json\n",
    "# fasttext.util.download_model('tr', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = lambda q_vector, vector : np.dot(q_vector, vector)/(norm(q_vector)*norm(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf idf utility functions\n",
    "\n",
    "# preprocessor for quesiton strings to transform strings to word arrays. \n",
    "# can be replaced with a better one (zemberek)\n",
    "def preProcessor(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# Gets the quesitons dictionary and returns dictionary of dictionaries \n",
    "# where subdictionaries consists of keys as each term and values as \n",
    "# number of occurencies.\n",
    "# This version treats all quesitons in a category as a whole document.  \n",
    "def TF(questions):\n",
    "    result = {}\n",
    "    for category in questions:\n",
    "        result[category] = {}\n",
    "        for question in questions[category]:\n",
    "            term_arr = preProcessor(question)\n",
    "            for term in term_arr:\n",
    "                if term not in result[category]:\n",
    "                    result[category][term] = 1\n",
    "                else:\n",
    "                    result[category][term] += 1\n",
    "    return result\n",
    "\n",
    "def normalizedTF(questions):\n",
    "    result = {}\n",
    "    tf = TF(questions)\n",
    "    for category in tf:\n",
    "        result[category] = {}\n",
    "        no_of_terms = len(tf[category])\n",
    "        for term in tf[category]:\n",
    "            result[category][term] = tf[category][term] / no_of_terms\n",
    "    return result\n",
    "\n",
    "# Calculates inverse document frequency of a term\n",
    "def IDF(term, questions):\n",
    "    number_of_documents = len(questions)\n",
    "    number_of_occurences = 0\n",
    "    tf = TF(questions)\n",
    "    for category in tf:\n",
    "        if term in tf[category]:\n",
    "            number_of_occurences+=1\n",
    "    if number_of_occurences == 0:\n",
    "        return 0\n",
    "    return 1 + np.log(number_of_documents / number_of_occurences)\n",
    "\n",
    "\n",
    "def TFxIDF(terms_string, questions):\n",
    "    result = {}\n",
    "    normal_tf = normalizedTF(questions)\n",
    "    terms = preProcessor(terms_string)\n",
    "\n",
    "    for category in normal_tf:\n",
    "        result[category] = {}\n",
    "        for term in terms:\n",
    "            idf = IDF(term, questions)\n",
    "            if term in normal_tf[category]:\n",
    "                result[category][term] = normal_tf[category][term] * idf\n",
    "            else:\n",
    "                result[category][term] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model(r'cc.tr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sifre': {'wifi': 0, 'şifremi': 0.3147918433002165, 'unuttum': 0.10493061443340551}, 'lisanslı yazılımlar': {'wifi': 0, 'şifremi': 0, 'unuttum': 0}, 'wifi': {'wifi': 0.32286342902586307, 'şifremi': 0, 'unuttum': 0}}\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./question_categories.json\")\n",
    "questions = json.load(f)\n",
    "\n",
    "print(TFxIDF(\"wifi şifremi unuttum\", questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vectors = {}\n",
    "for key in questions:\n",
    "    question_vectors[key] = []\n",
    "    for q in questions[key]:\n",
    "        question_vectors[key].append(ft.get_sentence_vector(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soru kategorisi: wifi\n",
      "En yakın soru: eduroam şifresi neydi\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Nasıl yardımcı olabilirim?\")\n",
    "q_vector = ft.get_sentence_vector(user_question)\n",
    "\n",
    "most_similar_question = \"\"\n",
    "most_similar_category = \"\"\n",
    "\n",
    "max_similarity = 0\n",
    "category_max_similarity = 0\n",
    "\n",
    "for key in question_vectors:\n",
    "    for vector, question in zip(question_vectors[key], questions[key]):\n",
    "        sim = cos_sim(q_vector, vector)\n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            most_similar_question = question\n",
    "            most_similar_category = key\n",
    "\n",
    "print(\"Soru kategorisi: %s\" % most_similar_category) \n",
    "print(\"En yakın soru: %s\" % most_similar_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
